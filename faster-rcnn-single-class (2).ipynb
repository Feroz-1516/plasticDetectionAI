{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Calculating mAP"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-09-05T06:09:16.945226Z","iopub.status.busy":"2023-09-05T06:09:16.944828Z","iopub.status.idle":"2023-09-05T06:09:31.127173Z","shell.execute_reply":"2023-09-05T06:09:31.126889Z","shell.execute_reply.started":"2023-09-05T06:09:16.945193Z"},"trusted":true},"outputs":[],"source":["from ultralytics import YOLO\n","from PIL import Image\n","import numpy as np\n","import pandas as pd\n","import torch\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","from torchvision import transforms as T\n","import torchvision\n","from super_gradients.training import models"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-09-05T06:09:33.572909Z","iopub.status.busy":"2023-09-05T06:09:33.572539Z","iopub.status.idle":"2023-09-05T06:09:33.580529Z","shell.execute_reply":"2023-09-05T06:09:33.580114Z","shell.execute_reply.started":"2023-09-05T06:09:33.572879Z"},"trusted":true},"outputs":[],"source":["def load_and_initialize_model_faster_rcnn(model_path):\n","    # Define your model architecture\n","    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False)\n","    num_classes = 2  # Modify this based on your dataset\n","    in_features = model.roi_heads.box_predictor.cls_score.in_features\n","    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n","\n","    # Load the saved model checkpoint\n","    checkpoint = torch.load(model_path,map_location=torch.device('cpu'))\n","\n","    # Load the model state and optimizer state\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","\n","    # Move the model to the GPU\n","    device = torch.device('cpu')\n","    model.to(device)\n","\n","    # Set the model to evaluation mode\n","    model.eval()\n","\n","    return model\n","\n","def load_and_initialize_model_yolo_v8(model_path):\n","  # Load a pretrained YOLOv8n model\n","  model = YOLO(model_path)\n","  return model\n","\n","def load_and_initialize_model_yolo_nas(path):\n","    \n","    modelyoloNas = models.get('yolo_nas_l',\n","                        num_classes=1,\n","                        checkpoint_path=path)\n","    return modelyoloNas\n","\n","def load_model():\n","\n","    model_path_rcnn=\"models/single_class_models/Singleclass_Faster_RCNN_125.pth\"\n","    model_path_yolo=\"models/single_class_models/YoloV8.onnx\"\n","    model_path_yolonas = \"models/single_class_models/YoloNAS.pth\"\n","    model_rcnn = load_and_initialize_model_faster_rcnn(model_path_rcnn)\n","    model_yolo = load_and_initialize_model_yolo_v8(model_path_yolo)\n","    model_yolonas = load_and_initialize_model_yolo_nas(model_path_yolonas)\n","    return model_rcnn,model_yolo,model_yolonas"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-09-05T06:09:34.428026Z","iopub.status.busy":"2023-09-05T06:09:34.427666Z","iopub.status.idle":"2023-09-05T06:09:34.432861Z","shell.execute_reply":"2023-09-05T06:09:34.432513Z","shell.execute_reply.started":"2023-09-05T06:09:34.427990Z"},"trusted":true},"outputs":[],"source":["def load_annotations_csv():\n","\n","    annotations = pd.read_csv(\"/kaggle/input/plastics-in-water-bodies-with-annotations/River data/Annotations/test_annotations_.csv\")\n","    image_ids = annotations['image_id'].unique()\n","\n","    ground_truths = {}\n","    for image_id in image_ids:\n","        image_annotations = annotations[annotations['image_id'] == image_id]\n","        boxes = image_annotations[['x1', 'y1', 'x2', 'y2']].values\n","        labels = torch.zeros(len(boxes), dtype=torch.int64)  # Assuming there is only one class (label 0)\n","        ground_truths[image_id] = {'boxes': boxes,\n","                                   'labels': np.array(labels)}\n","\n","    return ground_truths"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-09-05T06:10:46.646934Z","iopub.status.busy":"2023-09-05T06:10:46.646520Z","iopub.status.idle":"2023-09-05T06:10:46.658970Z","shell.execute_reply":"2023-09-05T06:10:46.658445Z","shell.execute_reply.started":"2023-09-05T06:10:46.646899Z"},"trusted":true},"outputs":[],"source":["def predict_on_single_image_rcnn(modelx, image_path, score_threshold=0.5):\n","\n","    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","    img = Image.open(image_path).convert('RGB')\n","    transform = T.Compose([T.ToTensor()])\n","    img_tensor = transform(img).unsqueeze(0).to(device)\n","    modelx.eval()\n","    with torch.no_grad():\n","        output = modelx(img_tensor)\n","\n","    boxes = output[0]['boxes'].cpu().detach().numpy()\n","    scores = output[0]['scores'].cpu().detach().numpy()\n","    labels = output[0]['labels'].cpu().detach().numpy()\n","#     print(output)\n","    # Filter out boxes with scores less than the threshold\n","    mask = scores >= score_threshold\n","    filtered_boxes = boxes[mask]\n","    filtered_scores = scores[mask]\n","    filtered_labels = labels[mask]\n","\n","    return {'boxes': filtered_boxes, 'scores': filtered_scores, 'labels': filtered_labels}\n","\n","def predict_on_single_image_yolo(modelx ,image_path):\n","  results = modelx(source=image_path,conf=0.1,iou=0.2)\n","  for result in results:\n","    boxes = result.boxes.xyxy\n","    scores = result.boxes.conf\n","    labels = result.boxes.cls\n","    boxes = boxes.cpu().numpy()\n","    scores = scores.cpu().numpy()\n","    labels = labels.cpu().numpy()\n","  results_dict = {'boxes': boxes, 'scores': scores, 'labels': labels}\n","  return results_dict\n","\n","def predict_on_single_image_yolonas(modelx ,image_path):\n","    # yolonas = best_model.predict(image_path,conf=0.4,iou=0.7).show()\n","    yolonas = modelx.predict(image_path,conf=0.45,iou=0.7)\n","\n","    for result in yolonas:\n","        yolovnas_preds = result.prediction.bboxes_xyxy\n","        nas_score = result.prediction.confidence\n","        labels = yolonas[0].prediction.labels\n","        \n","    results_dict = {'boxes': yolovnas_preds, 'scores': nas_score, 'labels': labels}\n","    return results_dict"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-09-05T06:09:35.453653Z","iopub.status.busy":"2023-09-05T06:09:35.453284Z","iopub.status.idle":"2023-09-05T06:09:35.464577Z","shell.execute_reply":"2023-09-05T06:09:35.464275Z","shell.execute_reply.started":"2023-09-05T06:09:35.453624Z"},"trusted":true},"outputs":[],"source":["# Apply non-maximum suppression to the concatenated predictions\n","def non_max_suppression(detections, threshold=0.5):\n","    # If there are no detections, return an empty list\n","    if len(detections) == 0:\n","        return []\n","\n","    # Sort detections by their y_max coordinates (bottom of the bounding box)\n","    sorted_indices = np.argsort(detections[:, 3])[::-1]\n","    detections = detections[sorted_indices]\n","\n","    # Initialize the list of selected detections\n","    selected_detections = []\n","\n","    while len(detections) > 0:\n","        # Select the detection with the highest y_max (bottom) coordinate\n","        current_detection = detections[0]\n","        selected_detections.append(current_detection)\n","\n","        # Calculate the overlap area with other detections\n","        x1_int = np.maximum(detections[1:, 0], current_detection[0])\n","        y1_int = np.maximum(detections[1:, 1], current_detection[1])\n","        x2_int = np.minimum(detections[1:, 2], current_detection[2])\n","        y2_int = np.minimum(detections[1:, 3], current_detection[3])\n","\n","        w_int = np.maximum(0, x2_int - x1_int + 1)\n","        h_int = np.maximum(0, y2_int - y1_int + 1)\n","        area_int = w_int * h_int\n","\n","        iou = area_int / ((current_detection[2] - current_detection[0] + 1) *\n","                          (current_detection[3] - current_detection[1] + 1) +\n","                          (detections[1:, 2] - detections[1:, 0] + 1) *\n","                          (detections[1:, 3] - detections[1:, 1] + 1) - area_int)\n","\n","        # Filter out detections with IoU above the threshold\n","        overlapping_indices = np.where(iou <= threshold)[0]\n","        detections = detections[overlapping_indices + 1]\n","\n","    return np.array(selected_detections)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-09-05T06:10:50.524920Z","iopub.status.busy":"2023-09-05T06:10:50.524562Z","iopub.status.idle":"2023-09-05T06:13:22.642936Z","shell.execute_reply":"2023-09-05T06:13:22.642519Z","shell.execute_reply.started":"2023-09-05T06:10:50.524890Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING  Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify', or 'pose'.\n","[2023-09-05 11:53:16] INFO - checkpoint_utils.py - Successfully loaded model weights from models/single_class_models/YoloNAS.pth EMA checkpoint.\n"]},{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/plastics-in-water-bodies-with-annotations/River data/Annotations/test_annotations_.csv'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[1;32md:\\object_detection\\Plastic_detection\\Plastic_detection\\faster-rcnn-single-class (2).ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/object_detection/Plastic_detection/Plastic_detection/faster-rcnn-single-class%20%282%29.ipynb#W6sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# Example usage\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/object_detection/Plastic_detection/Plastic_detection/faster-rcnn-single-class%20%282%29.ipynb#W6sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m test_image_folder \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/kaggle/input/plastics-in-water-bodies-with-annotations/River data/Test\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/object_detection/Plastic_detection/Plastic_detection/faster-rcnn-single-class%20%282%29.ipynb#W6sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m mAP_ensemble \u001b[39m=\u001b[39m calculate_mAP_for_ensemble(test_image_folder)\n","\u001b[1;32md:\\object_detection\\Plastic_detection\\Plastic_detection\\faster-rcnn-single-class (2).ipynb Cell 7\u001b[0m in \u001b[0;36mcalculate_mAP_for_ensemble\u001b[1;34m(test_image_folder)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/object_detection/Plastic_detection/Plastic_detection/faster-rcnn-single-class%20%282%29.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcalculate_mAP_for_ensemble\u001b[39m(test_image_folder):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/object_detection/Plastic_detection/Plastic_detection/faster-rcnn-single-class%20%282%29.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m# Load models and annotations\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/object_detection/Plastic_detection/Plastic_detection/faster-rcnn-single-class%20%282%29.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     model1, model2 ,model3\u001b[39m=\u001b[39m load_model()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/object_detection/Plastic_detection/Plastic_detection/faster-rcnn-single-class%20%282%29.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     ground_truths \u001b[39m=\u001b[39m load_annotations_csv()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/object_detection/Plastic_detection/Plastic_detection/faster-rcnn-single-class%20%282%29.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     test_results \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/object_detection/Plastic_detection/Plastic_detection/faster-rcnn-single-class%20%282%29.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     ensemble_predictions \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","\u001b[1;32md:\\object_detection\\Plastic_detection\\Plastic_detection\\faster-rcnn-single-class (2).ipynb Cell 7\u001b[0m in \u001b[0;36mload_annotations_csv\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/object_detection/Plastic_detection/Plastic_detection/faster-rcnn-single-class%20%282%29.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_annotations_csv\u001b[39m():\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/object_detection/Plastic_detection/Plastic_detection/faster-rcnn-single-class%20%282%29.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     annotations \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39m/kaggle/input/plastics-in-water-bodies-with-annotations/River data/Annotations/test_annotations_.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/object_detection/Plastic_detection/Plastic_detection/faster-rcnn-single-class%20%282%29.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     image_ids \u001b[39m=\u001b[39m annotations[\u001b[39m'\u001b[39m\u001b[39mimage_id\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39munique()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/object_detection/Plastic_detection/Plastic_detection/faster-rcnn-single-class%20%282%29.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     ground_truths \u001b[39m=\u001b[39m {}\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:934\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 934\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:1218\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1215\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1217\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1218\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1219\u001b[0m     f,\n\u001b[0;32m   1220\u001b[0m     mode,\n\u001b[0;32m   1221\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1222\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1223\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1224\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1225\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1226\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1227\u001b[0m )\n\u001b[0;32m   1228\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1229\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\common.py:786\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    782\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    785\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 786\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    787\u001b[0m             handle,\n\u001b[0;32m    788\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    789\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    790\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    791\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    792\u001b[0m         )\n\u001b[0;32m    793\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    794\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    795\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n","\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/plastics-in-water-bodies-with-annotations/River data/Annotations/test_annotations_.csv'"]},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["def calculate_mAP_for_ensemble(test_image_folder):\n","    # Load models and annotations\n","    model1, model2 ,model3= load_model()\n","    ground_truths = load_annotations_csv()\n","    test_results = []\n","    ensemble_predictions = None\n","    for image_id in ground_truths.keys():\n","        \n","        image_path = f\"{test_image_folder}/{image_id}.jpg\"\n","\n","        predictions_model1 = predict_on_single_image_rcnn(model1, image_path)\n","        predictions_model2 = predict_on_single_image_yolo(model2, image_path)\n","        predictions_model3 = predict_on_single_image_yolonas(model3, image_path)\n","\n","        # Concatenate the predictions from both models\n","        all_predictions = np.vstack((predictions_model1['boxes'], predictions_model2['boxes'],predictions_model3['boxes']))\n","        ensemble_predictions = non_max_suppression(all_predictions)\n","        test_results.append((ensemble_predictions, ground_truths[image_id]))\n","    return test_results\n","\n","# Example usage\n","test_image_folder = r\"/kaggle/input/plastics-in-water-bodies-with-annotations/River data/Test\"\n","mAP_ensemble = calculate_mAP_for_ensemble(test_image_folder)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-05T06:13:35.417061Z","iopub.status.busy":"2023-09-05T06:13:35.416702Z","iopub.status.idle":"2023-09-05T06:13:35.420402Z","shell.execute_reply":"2023-09-05T06:13:35.420034Z","shell.execute_reply.started":"2023-09-05T06:13:35.417030Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["30\n"]}],"source":["print(len(mAP_ensemble))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-05T06:16:39.761611Z","iopub.status.busy":"2023-09-05T06:16:39.761245Z","iopub.status.idle":"2023-09-05T06:16:39.923010Z","shell.execute_reply":"2023-09-05T06:16:39.922694Z","shell.execute_reply.started":"2023-09-05T06:16:39.761581Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Mean Average Precision (mAP): 0.9419797270439686\n"]}],"source":["import numpy as np\n","from sklearn.metrics import average_precision_score\n","\n","def calculate_mAP(predictions_list):\n","    num_classes = 1\n","    thresh = 0.225\n","    mAP_sum = 0.0\n","    num_images = len(predictions_list)\n","\n","    for i in range(num_images):\n","        predictions, gt_boxes_i = predictions_list[i]\n","\n","        # Calculate Average Precision for each class\n","        ap_sum = 0.0\n","        for c in range(num_classes):\n","            pred_boxes_c = predictions\n","            gt_boxes_c = gt_boxes_i['boxes'][np.where(gt_boxes_i['labels'] == c)[0]]\n","\n","            if len(gt_boxes_c) == 0 or len(pred_boxes_c) == 0:\n","                continue\n","\n","            iou_matrix = calculate_iou(pred_boxes_c, gt_boxes_c)\n","            tp_indices = np.where(iou_matrix >= thresh)[0]\n","            num_true_positives = len(tp_indices)\n","            ap_sum += num_true_positives / len(gt_boxes_c)\n","\n","        ap = ap_sum / num_classes\n","        mAP_sum += ap\n","\n","    mean_ap = mAP_sum / num_images\n","    return mean_ap\n","\n","\n","def calculate_iou(boxes1, boxes2):\n","    iou_matrix = np.zeros((len(boxes1), len(boxes2)))\n","\n","    for i in range(len(boxes1)):\n","        for j in range(len(boxes2)):\n","            x1 = max(boxes1[i, 0], boxes2[j, 0])\n","            y1 = max(boxes1[i, 1], boxes2[j, 1])\n","            x2 = min(boxes1[i, 2], boxes2[j, 2])\n","            y2 = min(boxes1[i, 3], boxes2[j, 3])\n","\n","            intersection = max(0, x2 - x1) * max(0, y2 - y1)\n","            area_boxes1 = (boxes1[i, 2] - boxes1[i, 0]) * (boxes1[i, 3] - boxes1[i, 1])\n","            area_boxes2 = (boxes2[j, 2] - boxes2[j, 0]) * (boxes2[j, 3] - boxes2[j, 1])\n","            union = area_boxes1 + area_boxes2 - intersection\n","\n","            iou_matrix[i, j] = intersection / (union + np.finfo(np.float64).eps)\n","\n","    return iou_matrix\n","\n","mAP = calculate_mAP(mAP_ensemble)\n","print(\"Mean Average Precision (mAP):\", mAP)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
